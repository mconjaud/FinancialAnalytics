---
title: "Financial Analytics - Trabalho Final"
authors:
  - name: Michel Maurice Conjaud
  - name: Hélio Pereira Oliveira
  - name: Renan Cabral
  - name: Tiago Evangelista Pardo
format:
  html:
    code-fold: true
    embed-resources: true
    smooth-scroll: true
    theme: cerulean
    toc: true
    toc-expand: true
    toc-title: "Sumário"
    toc_float: true

execute:
  freeze: true
  warning: false
  cache: true
---

# 0. Bibliotecas e Importação de Dados

Bibliotecas
```{r}
#| output: false
library(ggplot2)
library(fpp3)
library(rugarch)
library(tsibble)
library(yfR)
library(zoo)
library(xts)
library(lubridate)
library(patchwork)
library(lmtest)
library(fGarch)

library(xts)
```

Seleção das Ações/Ativos e definição da data de início: 01/01/2019
```{r}

start_date <- '2019-01-01'

ativos <- c(
  "NVDC34.SA",
  "BCSA34.SA", 
  "AMZO34.SA",
  "RENT3.SA",
  "PRIO3.SA",
  "TASA4.SA"
)
```

Selecionando as ações

```{r}
da <- yfR::yf_get(
  ativos,
  first_date = start_date,
  last_date = Sys.Date(),
  bench_ticker = "^BVSP",
  type_return = "log",
  freq_data = "daily",
  do_complete_data = TRUE
)
view(da)

```

Data mínima comum a todas as séries

```{r}
# Capturando menor data da base 
data_corte <- da |>
  dplyr::group_by(ticker) |>
  dplyr::filter(ref_date == min(ref_date)) |>
  dplyr::ungroup() |>
  with(max(ref_date))

data_corte
```

```{r}
# Df com data mínima
da_train <- da |>
  dplyr::filter(ref_date > data_corte) 

view(da_train)  
```


Transformando dataframe em tsbible 

```{r}
#| output: false

da_tsibble <- da_train |>
  as_tsibble(key = ticker, index = ref_date, regular = FALSE)

View(da_tsibble)

```


# 1. Gráficos de Preço, Retorno e Avaliação de Heterodasticidade Condicional


## 1.1. Gráfico de preços e dos log retornos

### 1.1.1. Preços

```{r}
#Função para formatar legenda
quarter_label <- function(x) {
  paste0(year(x), "Q", quarter(x))
}
```


```{r}
#criando gráfico da série de preços
da_tsibble |>
  autoplot(price_adjusted, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1)+
  scale_x_date(date_breaks = "4 months", label=quarter_label) +
  labs ( title = "Série de Preço", y = "Preço", x = "Data") +
  theme(plot.title = element_text(hjust = 0.1))
```  


### 1.1.2. Log Retornos

```{r}
#criando gráfico da série de retornos
da_tsibble |>
  autoplot(ret_adjusted_prices, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1) +
  scale_x_date(date_breaks = "4 months", labels = quarter_label) +
  labs ( title = "Série de Log Retornos", y = "Log Retornos", x = "Data") +
  theme(plot.title = element_text(hjust = 0.5))

```

## 1.2 Analisando possível heterocedasticidade condicional

Criação do log retorno ao quadrado (proxi da volatilidade)


```{r}
da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2) |>
  autoplot(ret2, colour = "black") +
  facet_wrap(~ticker, ncol = 1)

```

**Verificando a existência de heterodasticidade condicional através dos seguintes métodos:**

* 1.2.1. ACF dos retornos quadráticos

* 1.2.2. Teste Ljung-Box dos retornos quadráticos

* 1.2.3. Teste Langrange Multiplier

### 1.2.1. ACF dos retornos ao quadrado

```{r}
# Gerando variável dos retornos quadráticos
da_tsibble  <-  da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2)
```

```{r}
#ACF dos retornos ao quadrado
da_tsibble |>
  ACF(ret2) |>
  autoplot()
```

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! INSERIR CONCLUSÃO AQUI !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


### 1.2.2. Teste Ljung-Box
```{r}

resultados <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)
  
  # Realizar o teste Box-Ljung
  box_test_result <- Box.test(da_tsibble_filtered$ret2, type = "Ljung-Box")
  
  # Adicionar o resultado ao dataframe de resultados
  resultados <- rbind(resultados, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = box_test_result$p.value 
                                          ))
}

print(resultados)
```

* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, RENT3.SA, PRIO3.SA e TASA4.SA, AMZO34.SA

### 1.2.3. Teste Lagrange Multiplier
```{r}
library(FinTS)

resultados_ml <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)

  teste_ml <- ArchTest(da_tsibble_filtered$ret_closing_prices)

  # Adicionar o resultado ao dataframe de resultados
  resultados_ml <- rbind(resultados_ml, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = teste_ml$p.value 
                                          ))
}

print(resultados_ml)
```

* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, AMZO34.SA, RENT3.SA, PRIO3.SA, e TASA4.SA

# 2. Ajustando modelos Arch / Garch

## 2.1. Santander

### 2.1.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Santander
santander <- da_tsibble %>%
  subset(ticker=='BCSA34.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(santander[,-1],order.by = ymd(santander$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.1.2. Análises da série

#### 2.1.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.1.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))

```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal


```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)

```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.1.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal


```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.1.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.1.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.1.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!INSERIR CONCLUSÃO AQUI!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


### 2.1.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Criação inicial do data frame vazio
comparacao_forecast <- data.frame(Empresa = character(), meanForecast = double(), meanError = double(), standardDeviation = double())

# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Santander",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```


## 2.2. AMZO34.SA

### 2.2.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
amazon <- da_tsibble %>%
  subset(ticker=='AMZO34.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(amazon[,-1],order.by = ymd(amazon$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.2.2. Análises da série

#### 2.2.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

#### 2.2.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.2.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.2.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.2.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.2.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.2.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Amazon",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.3. Localiza

### 2.3.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
localiza <- da_tsibble %>%
  subset(ticker=='RENT3.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(localiza[,-1],order.by = ymd(localiza$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.3.2. Análises da série

#### 2.3.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.3.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.3.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.3.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.3.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.3.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.3.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Localiza" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Localiza",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.4. Prio

### 2.4.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
prio <- da_tsibble %>%
  subset(ticker=='PRIO3.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(prio[,-1],order.by = ymd(prio$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.4.2. Análises da série

#### 2.4.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.4.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.4.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.4.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.4.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.4.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.4.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Prio",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.5. Taurus

### 2.5.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
taurus <- da_tsibble %>%
  subset(ticker=='TASA4.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(taurus[,-1],order.by = ymd(taurus$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.5.2. Análises da série

#### 2.5.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.5.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.5.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.5.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.5.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.5.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```

### 2.5.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Taurus",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.6. NVDC34.SA

### 2.6.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
nvidia <- da_tsibble %>%
  subset(ticker=='NVDC34.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(nvidia[,-1],order.by = ymd(nvidia$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.6.2. Análises da série

#### 2.6.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.6.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```

**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.6.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.6.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.6.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.6.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.6.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Nvidia",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```


# 3. Comparação de Volatilidades
```{r}
comparacao_forecast
```

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! INSERIR INTERPRETAÇÃO AQUI !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


