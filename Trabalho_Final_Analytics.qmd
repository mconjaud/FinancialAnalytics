---
title: "Financial Analytics - Trabalho Final"
authors:
  - name: Michel Maurice Conjaud
  - name: Hélio Pereira Oliveira
  - name: Renan Cabral
  - name: Tiago Evangelista Pardo
format:
  html:
    code-fold: true
    embed-resources: true
    smooth-scroll: true
    theme: cerulean
    toc: true
    toc-expand: true
    toc-title: "Sumário"
    toc_float: true

execute:
  freeze: true
  warning: false
  cache: true
---

# 0. Bibliotecas e Importação de Dados

Bibliotecas
```{r}
#| output: false
library(ggplot2)
library(fpp3)
library(rugarch)
library(tsibble)
library(yfR)
library(zoo)
library(xts)
library(lubridate)
library(patchwork)
library(lmtest)
library(fGarch)
library(xts)
```

Seleção das Ações/Ativos e definição da data de início: 01/01/2019
```{r}

start_date <- '2019-01-01'

ativos <- c(
  "NVDC34.SA",
  "BCSA34.SA", 
  "AMZO34.SA",
  "RENT3.SA",
  "PRIO3.SA",
  "TASA4.SA"
)
```

Selecionando as ações

```{r}
da <- yfR::yf_get(
  ativos,
  first_date = start_date,
  last_date = Sys.Date(),
  bench_ticker = "^BVSP",
  type_return = "log",
  freq_data = "daily",
  do_complete_data = TRUE
)
view(da)

```

Data mínima comum a todas as séries

```{r}
# Capturando menor data da base 
data_corte <- da |>
  dplyr::group_by(ticker) |>
  dplyr::filter(ref_date == min(ref_date)) |>
  dplyr::ungroup() |>
  with(max(ref_date))

data_corte
```

```{r}
# Df com data mínima
da_train <- da |>
  dplyr::filter(ref_date > data_corte) 

view(da_train)  
```


Transformando dataframe em tsbible 

```{r}
#| output: false

da_tsibble <- da_train |>
  as_tsibble(key = ticker, index = ref_date, regular = FALSE)

View(da_tsibble)

```


# 1. Gráficos de Preço, Retorno e Avaliação de Heterodasticidade Condicional


## 1.1. Gráfico de preços e dos log retornos

### 1.1.1. Preços

```{r}
#Função para formatar legenda
quarter_label <- function(x) {
  paste0(year(x), "Q", quarter(x))
}
```


```{r}
#criando gráfico da série de preços
da_tsibble |>
  autoplot(price_adjusted, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1)+
  scale_x_date(date_breaks = "4 months", label=quarter_label) +
  labs ( title = "Série de Preço", y = "Preço", x = "Data") +
  theme(plot.title = element_text(hjust = 0.1))
```  


### 1.1.2. Log Retornos

```{r}
#criando gráfico da série de retornos
da_tsibble |>
  autoplot(ret_adjusted_prices, colour = "black") +
  facet_wrap(~ticker, scales = "free_y", ncol = 1) +
  scale_x_date(date_breaks = "4 months", labels = quarter_label) +
  labs ( title = "Série de Log Retornos", y = "Log Retornos", x = "Data") +
  theme(plot.title = element_text(hjust = 0.5))

```

## 1.2 Analisando possível heterocedasticidade condicional

Criação do log retorno ao quadrado (proxi da volatilidade)


```{r}
da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2) |>
  autoplot(ret2, colour = "black") +
  facet_wrap(~ticker, ncol = 1)

```

**Verificando a existência de heterodasticidade condicional através dos seguintes métodos:**

* 1.2.1. ACF dos retornos quadráticos

* 1.2.2. Teste Ljung-Box dos retornos quadráticos

* 1.2.3. Teste Langrange Multiplier

### 1.2.1. ACF dos retornos ao quadrado

```{r}
# Gerando variável dos retornos quadráticos
da_tsibble  <-  da_tsibble |>
  dplyr::mutate(ret2 = ret_closing_prices^2)
```

```{r}
#ACF dos retornos ao quadrado
da_tsibble |>
  ACF(ret2) |>
  autoplot()
```

**Interpretação**
* AMZO3, BCSA3, PRIO3 e RENT3 mostram autocorrelações significativas nos primeiros lags, indicando que a volatilidade desses retornos pode ser dependente no tempo. 

* NVCD, por outro lado, não apresenta uma dependência temporal forte, sugerindo ausência de heterocedasticidade significativa. 

* TASA4 tem algumas autocorrelações significativas, mas menos pronunciadas em comparação com as outras séries.


### 1.2.2. Teste Ljung-Box
```{r}

resultados <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)
  
  # Realizar o teste Box-Ljung
  box_test_result <- Box.test(da_tsibble_filtered$ret2, type = "Ljung-Box")
  
  # Adicionar o resultado ao dataframe de resultados
  resultados <- rbind(resultados, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = box_test_result$p.value 
                                          ))
}

print(resultados)
```

* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, RENT3.SA, PRIO3.SA e TASA4.SA, AMZO34.SA

### 1.2.3. Teste Lagrange Multiplier
```{r}
library(FinTS)

resultados_ml <- data.frame(Empresa = character(), "P-Valor" = numeric())

for (empresa in ativos) {
  # Filtrar o dataframe para a empresa atual
  da_tsibble_filtered <- da_tsibble |> filter(ticker == empresa)

  teste_ml <- ArchTest(da_tsibble_filtered$ret_closing_prices)

  # Adicionar o resultado ao dataframe de resultados
  resultados_ml <- rbind(resultados_ml, 
                               data.frame(Empresa = empresa, 
                                          "P-Valor" = teste_ml$p.value 
                                          ))
}

print(resultados_ml)
```

* Não rejeita a hipótese nula: NVDC34.SA

* Rejeitam a hipótese nula: BCSA34.SA, AMZO34.SA, RENT3.SA, PRIO3.SA, e TASA4.SA

# 2. Ajustando modelos Arch / Garch

## 2.1 Fit e Escolha do melhor modelo para cada ação (Menor AIC)

```{r} 
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()
resultados_tidy <- list()

distribuicao_erro  <- c("norm", "std")

  for (empresa in unique(da_tsibble$ticker)) {
    retornos <- da_tsibble %>%
    subset(ticker== empresa) %>%
    select(ref_date,ret_closing_prices)
  ret <- xts(retornos[,-1],order.by = ymd(retornos$ref_date))[-1,]
  ret2 = ret**2
  plot(ret2)

    # Loop pelos parâmetros de tipo de distribuição e m e n
    for (distribuicao in distribuicao_erro) {
      for (m in 1:3) {
        for (n in 0:3) {
        
          # Definir a fórmula do modelo com os parâmetros m e n atuais
          formula_garch <- paste0("~garch(", m, ",", n, ")")

          # Ajustar o modelo GARCH
          modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                                   include.mean = TRUE, cond.dist = distribuicao)

          # Armazenar o modelo ajustado na lista para visualização detalhada
          modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao, "_", empresa)]] <- modelo_atual
          # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
          ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao, "_", empresa)]] <- modelo_atual@fit$ics
        }
      }
    }

    # Formatando resultados para melhor visualização 
    for (nome_modelo in names(ics_modelos_garch)) {
      valores <- ics_modelos_garch[[nome_modelo]]
      df <- data.frame(
        AIC = valores["AIC"],
        BIC = valores["BIC"]
      )
        resultados_tidy[[nome_modelo]] <- df
    }
    } 
    resultados_tidy_df <- do.call(rbind, resultados_tidy)

resultados_tidy_df  %>% rownames_to_column()  %>% 
                          separate(rowname, c("Modelo", "m", "n", "dist", "ticker"),
                          sep = "_")  %>% 
                          arrange(AIC)  %>% 
                          distinct(ticker, .keep_all = TRUE)
                          
```

### 2.1.2. Avaliação do melhor modelo de cada ação

Análise detalhada do melhor modelo de cada ação pelos critérios de informação
```{r}

Resumo_AMAZO34 <- summary(modelos_garch$garch_1_2_std_AMZO34.SA)
Resumo_BCSA34 <- summary(modelos_garch$garch_1_1_std_BCSA34.SA)
Resumo_RENT3 <- summary(modelos_garch$garch_2_1_std_RENT3.SA)
Resumo_TASA4 <- summary(modelos_garch$garch_1_1_std_TASA4.SA)
Resumo_NVDC34 <- summary(modelos_garch$garch_1_1_std_NVDC34.SA)
Resumo_PRIO3 <- summary(modelos_garch$garch_1_1_std_PRIO3.SA)

print(Resumo_AMAZO34)
print(Resumo_BCSA34)
print(Resumo_RENT3)
print(Resumo_TASA4)
print(Resumo_NVDC34)
print(Resumo_PRIO3)

```

**Interpretação**

* Baseado nos coeficientes e nos critérios de informação:

* Melhor Modelo Geral: AMAZON34 devido aos melhores valores de log-likelihood, AIC e BIC.
* Maior Reatividade a Choques: TASA4 e BCSA34 têm altos valores de alpha1.
* Maior Persistência da Volatilidade: PRIO3 e TASA4 com altos valores de beta1.

* Os modelos AMAZON34 e BCSA34 parecem ser bem ajustados, com AMAZON34 tendo uma leve vantagem em termos de qualidade do ajuste.

### 2.1.3. Análise dos retornos e volatilidade 

Gráfico dos retornos de cada ação
```{r}

retornos <- da_tsibble %>%
    select(ref_date,ret_closing_prices)
  ret <- xts(retornos[,-1],order.by = ymd(retornos$ref_date))[-1,]

da_tsibble |>
  dplyr::mutate(ret = ret_closing_prices) |>
  autoplot(ret, colour = "black") +
  facet_wrap(~ticker, ncol = 1)

```

Gráfico da volatilidade de cada ação
```{r}

# Gráfico de 'Volatilidade AMZO34.SA'
sigma <- xts(cbind(modelos_garch$garch_1_2_std_AMZO34.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade AMZO34.SA")

# Gráfico de 'Volatilidade BCSA34.SA'
sigma <- xts(cbind(modelos_garch$garch_1_1_std_BCSA34.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade BCSA34.SA")

# Gráfico de 'Volatilidade PRIO3.SA'
sigma <- xts(cbind(modelos_garch$garch_1_1_std_PRIO3.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade PRIO3.SA")

# Gráfico de 'Volatilidade NVDC34.SA'
sigma <- xts(cbind(modelos_garch$garch_1_1_std_NVDC34.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade NVDC34.SA")

# Gráfico de 'Volatilidade TASA4.SA'
sigma <- xts(cbind(modelos_garch$garch_1_1_std_TASA4.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade TASA4.SA")

# Gráfico de 'Volatilidade BCSA34.SA'
sigma <- xts(cbind(modelos_garch$garch_1_1_std_BCSA34.SA@sigma.t), order.by = index(ret))
plot(sigma, auto.legend = TRUE, legend.loc = "top", main = "Volatilidade BCSA34.SA")

```


```{r}

model_names <- c(
  "garch_1_2_std_AMZO34.SA",
  "garch_1_1_std_BCSA34.SA",
  "garch_1_1_std_PRIO3.SA",
  "garch_1_1_std_NVDC34.SA",
  "garch_1_1_std_TASA4.SA",
  "garch_1_1_std_BCSA34.SA"
)
titles <- c(
  "Volatilidade AMZO34.SA",
  "Volatilidade BCSA34.SA",
  "Volatilidade PRIO3.SA",
  "Volatilidade NVDC34.SA",
  "Volatilidade TASA4.SA",
  "Volatilidade BCSA34.SA"
)

par(mfrow = c(6, 1)) 

for (i in 1:length(model_names)) {
  model_name <- model_names[i]
  title <- titles[i]
  
  model <- modelos_garch[[model_name]]
  sigma <- xts(cbind(model@sigma.t), order.by = index(ret))
  
  plot(sigma, main = title)
}
```

## 2.1.4. Análise dos resíduos
```{r}

residuos <- list()

for (i in 1:nrow(resultados_tidy_df
                          )) {
  # Concatenando o nome do modelo para ficar como consta no objeto modelos_garch
  model_name <- paste0(resultados_tidy_df$Modelo[i], "_", resultados_tidy_df$m[i], "_", resultados_tidy_df$n[i], "_", resultados_tidy_df$dist[i], "_", resultados_tidy_df$ticker[i])
  
  # Checando se o modelo está entre os melhores
  if (model_name %in% names(modelos_garch)) {
    # Acessando os melhores modelos e calculando resíduos
    current_model <- modelos_garch[[model_name]]
    residuos[[model_name]] <- residuals(current_model, standardize = TRUE)
  }
}
str(residuos)

```


















## 2.1. Santander

### 2.1.2. Análises da série

#### 2.1.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.1.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))

```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal


```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)

```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.1.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```


### 2.1.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(summary(modelos_garch$garch_1_1_std))
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.1.4. Verificação dos resíduos
```{r}
residuos  <- residuals(min_AIC_STD, standardize=T)

par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.1.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!INSERIR CONCLUSÃO AQUI!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


### 2.1.6. Previsão
Realizando previsão
```{r}
forecast <- predict(min_AIC_STD$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Criação inicial do data frame vazio
comparacao_forecast <- data.frame(Empresa = character(), meanForecast = double(), meanError = double(), standardDeviation = double())

# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Santander",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```


## 2.2. AMZO34.SA

### 2.2.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
amazon <- da_tsibble %>%
  subset(ticker=='AMZO34.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(amazon[,-1],order.by = ymd(amazon$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.2.2. Análises da série

#### 2.2.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

#### 2.2.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.2.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.2.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.2.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.2.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.2.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Amazon",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.3. Localiza

### 2.3.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
localiza <- da_tsibble %>%
  subset(ticker=='RENT3.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(localiza[,-1],order.by = ymd(localiza$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.3.2. Análises da série

#### 2.3.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.3.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.3.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.3.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.3.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.3.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.3.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Localiza" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Localiza",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.4. Prio

### 2.4.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
prio <- da_tsibble %>%
  subset(ticker=='PRIO3.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(prio[,-1],order.by = ymd(prio$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.4.2. Análises da série

#### 2.4.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.4.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.4.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.4.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.4.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.4.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.4.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Prio",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.5. Taurus

### 2.5.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
taurus <- da_tsibble %>%
  subset(ticker=='TASA4.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(taurus[,-1],order.by = ymd(taurus$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.5.2. Análises da série

#### 2.5.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.5.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```
**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.5.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.5.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.5.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.5.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```

### 2.5.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Taurus",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```

## 2.6. NVDC34.SA

### 2.6.1. Filtrando a base e selecionando variáveis
```{r} 
# filtrando pela empresa Nvidia
nvidia <- da_tsibble %>%
  subset(ticker=='NVDC34.SA') %>%
  select(ref_date,ret_closing_prices)
ret <- xts(nvidia[,-1],order.by = ymd(nvidia$ref_date))[-1,]
ret2 = ret**2
plot(ret2)

```

### 2.6.2. Análises da série

#### 2.6.2.1. Autocorrelação dos retornos e volatilidade
```{r}
par(mfrow=c(1,2))
acf(ret,60,na.action = na.pass)
acf(ret2,60,na.action = na.pass)
```

**Interpretação**

* A série de retornos apresenta alguns lags de autocorrelação ligeiramente fora do intervalo de confiança. É possível que o modelo se beneficie de inserção de parâmetros p e q.
* A série de retornos ao quadrado apresenta autocorrelação relevante até o lag 7. Portanto, utilizaremos o modelo Arch 7 além de realizar looping dos das combinações dos parâmetros de 1 a 3 para m e n.

#### 2.6.2.2. Normalidade: Shapiro teste e gráficos
```{r}
shapiro.test(as.vector(ret))
```

**Interpretação**

* O teste Shapiro Wilk informa que a série não possui distribuição normal

```{r}
par(mfrow=c(1,2))
h <- hist(ret, breaks=20, col="red", xlab="", 
          main="Histogram") 
xfit <- seq(min(ret),max(ret),length=40) 
yfit <- dnorm(xfit,mean=mean(ret),sd=sd(ret)) 
yfit <- yfit*diff(h$mids[1:2])*length(ret) 
lines(xfit, yfit, col="blue", lwd=2)


qqnorm(ret, pch = 1, frame = FALSE)
qqline(ret, col = "steelblue", lwd = 2)
```

**Interpretação**

* Os gráficos permitem que visualizemos que a distribuição não é normal, apresentando "caudas pesadas" características de séries desta natureza. Isso sugere que parâmetros de distribuição não normais devem ter melhor desempenho.

### 2.6.2. Fit do modelo

looping de parâmetros com distribuição de erros T-Student e normal

```{r}
# Lista para comparação de modelos
modelos_garch <- list()
ics_modelos_garch  <- list()

distribuicao_erro  <- c("norm", "std")

# Loop pelos parâmetros de tipo de distribuição e m e n
for (distribuicao in distribuicao_erro) {
  for (m in 1:3) {
    for (n in 0:3) {

      # Definir a fórmula do modelo com os parâmetros m e n atuais
      formula_garch <- paste0("~garch(", m, ",", n, ")")

      # Ajustar o modelo GARCH
      modelo_atual <- garchFit(formula = as.formula(formula_garch), data = ret, trace = FALSE, 
                               include.mean = TRUE, cond.dist = distribuicao)

      # Armazenar o modelo ajustado na lista para visualização detalhada
      modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual
      # Armazenar o modelo ajustado na lista para comparação dos critérios de informação
      ics_modelos_garch[[paste0("garch_", m, "_", n, "_", distribuicao)]] <- modelo_atual@fit$ics
    }
  }
}

# Formatando resultados para melhor visualização 
resultados_tidy <- list()

for (nome_modelo in names(ics_modelos_garch)) {
  valores <- ics_modelos_garch[[nome_modelo]]
  df <- data.frame(
    AIC = valores["AIC"],
    BIC = valores["BIC"]
  )
    resultados_tidy[[nome_modelo]] <- df
}

resultados_tidy_df <- do.call(rbind, resultados_tidy)

print(resultados_tidy_df)

```

### 2.6.3. Avaliação do melhor modelo

Análise detalhada do melhor modelo pelos critérios de informação: garch_1_1_std
```{r}
summary(modelos_garch$garch_1_1_std)
```

**Interpretação**

* Significância em todos os níveis em todos os estimadores do modelo
*  Os testes Ljung-Box e LM Arch Test não rejeitam a hipótese nula de homocedasticidade dos resíduos, o que indica uma boa modelagem.

### 2.6.4. Verificação dos resíduos
```{r}
residuos  <- residuals(modelos_garch$garch_1_1_std, standardize=T)
par(mfrow=c(1,2))
ts.plot(residuos)
acf(residuos)
```

### 2.6.5. Análise dos retornos e volatilidade 

```{r}
par(mfrow=c(2,1))
plot(ret)
sigma <- xts(cbind(modelos_garch$garch_1_1_std@sigma.t),order.by = index(ret))
colnames(sigma) <- c("Volatilidade")
plot(sigma,auto.legend=T,legend.loc = "top",main='')
```


### 2.6.6. Previsão
Realizando previsão
```{r}
forecast <- predict(modelos_garch$garch_1_1_std, n.ahead = 1)
forecast
```

Salvando resultado em tabela
```{r}
# Adicionando os resultados da previsão para a "Amazon" ao data frame
comparacao_forecast <- rbind(comparacao_forecast, 
                             data.frame(Empresa = "Nvidia",
                                        meanForecast = forecast$meanForecast,
                                        meanError = forecast$meanError,
                                        standardDeviation = forecast$standardDeviation))
```


# 3. Comparação de Volatilidades
```{r}
comparacao_forecast
```

!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! INSERIR INTERPRETAÇÃO AQUI !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!


